
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Specify the path of the zipped dataset\n",
    "zip_file_path = '/Users/rahul.g/Desktop/drive-download-20241201T152444Z-001.zip'  # Dataset path\n",
    "extract_dir = './dataset'\n",
    "\n",
    "# Step 2: Extract the zipped dataset\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "# Verify the dataset structure\n",
    "print(\"Extracted files:\")\n",
    "print(os.listdir(extract_dir))\n",
    "\n",
    "# Ensure directories exist\n",
    "GOOD_IMAGES_DIR = os.path.join(extract_dir, 'good')\n",
    "BAD_IMAGES_DIR = os.path.join(extract_dir, 'bad')\n",
    "\n",
    "if not os.path.exists(GOOD_IMAGES_DIR) or not os.path.exists(BAD_IMAGES_DIR):\n",
    "    raise FileNotFoundError(\"Ensure the dataset contains 'good' and 'bad' directories.\")\n",
    "else:\n",
    "    print(\"Dataset structure verified. Proceeding to training.\")\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = (128, 128)  # Resize images to 128x128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Data Preparation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # 20% of data for validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    extract_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    extract_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Visualize some sample images\n",
    "def plot_samples(generator, title):\n",
    "    images, labels = next(generator)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):  # Display 9 images\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Label: {'Bad' if labels[i] == 1 else 'Good'}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(train_generator, \"Training Data Samples\")\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Visualize Training and Validation Accuracy/Loss\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Save Model\n",
    "model.save('./scratch_detection_model.h5')\n",
    "\n",
    "# Testing on a Single Image\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    prediction = model.predict(img_array)\n",
    "    return \"Bad Image\" if prediction[0] > 0.5 else \"Good Image\"\n",
    "\n",
    "# Test Example\n",
    "test_image_path = os.path.join(BAD_IMAGES_DIR, os.listdir(BAD_IMAGES_DIR)[0])  # Replace with actual test image path if needed\n",
    "result = predict_image(test_image_path)\n",
    "print(f\"Prediction for test image: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d52f35-2ce9-4b69-bcc0-259fa921ade8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
